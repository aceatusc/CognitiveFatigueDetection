{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1354 valid samples\n",
      "Fractal Features Shape: torch.Size([4, 41, 41])\n",
      "Signal Shape: torch.Size([4, 1000])\n",
      "Labels: {'before_label': tensor(0), 'after_label': tensor(0)}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MatFileDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.features = []  # Will store multi-channel fractal features (num_channels, feature_length)\n",
    "        self.signals = []   # Will store multi-channel EEG signals (num_channels, signal_length)\n",
    "        self.labels = []    # Labels for each window (before_label, after_label)\n",
    "        self.num_channels = 4  # Number of channels (4 separate .mat files)\n",
    "        self.fractal_feature_length = None  # To determine feature length from first valid data\n",
    "\n",
    "        self._load_data(directory)\n",
    "        self._validate_labels()\n",
    "\n",
    "    def _load_data(self, directory):\n",
    "        \"\"\"Load all four channels separately and align participant data correctly.\"\"\"\n",
    "        # Step 1: Find all .mat files (assuming four files exist, one per channel)\n",
    "        mat_files = sorted([os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".mat\")])\n",
    "        if len(mat_files) != self.num_channels:\n",
    "            raise ValueError(f\"Expected {self.num_channels} .mat files, but found {len(mat_files)}\")\n",
    "\n",
    "        # Step 2: Load data from all channels\n",
    "        all_channels_data = [sio.loadmat(f, struct_as_record=False, squeeze_me=True) for f in mat_files]\n",
    "\n",
    "        # Step 3: Check if all files contain 'all_window_features'\n",
    "        for i, mat_data in enumerate(all_channels_data):\n",
    "            if \"all_window_features\" not in mat_data:\n",
    "                raise ValueError(f\"Missing 'all_window_features' in file {mat_files[i]}\")\n",
    "\n",
    "        # Step 4: Process participant data by aligning across channels\n",
    "        num_participants = len(all_channels_data[0][\"all_window_features\"])\n",
    "        \n",
    "        for participant_idx in range(num_participants):\n",
    "            # Extract participant data from each channel\n",
    "            participant_windows = [\n",
    "                mat_data[\"all_window_features\"][participant_idx] for mat_data in all_channels_data\n",
    "            ]\n",
    "\n",
    "            # Skip if any channel is missing participant data\n",
    "            if any(p is None for p in participant_windows):\n",
    "                continue\n",
    "\n",
    "            # Step 5: Ensure that windows are aligned across channels\n",
    "            num_windows = len(participant_windows[0])  # Get window count from first channel\n",
    "            for win_idx in range(num_windows):\n",
    "                # Extract corresponding window from each channel\n",
    "                window_data = [participant_windows[ch][win_idx] for ch in range(self.num_channels)]\n",
    "\n",
    "                # Extract labels from the first channel only (assuming labels are the same across channels)\n",
    "                before_label = getattr(window_data[0], \"before_label\", None)\n",
    "                after_label = getattr(window_data[0], \"after_label\", None)\n",
    "\n",
    "                # Validate labels\n",
    "                if (before_label is None or after_label is None or \n",
    "                    not (0 <= before_label <= 3) or not (0 <= after_label <= 3)):\n",
    "                    continue  # Skip invalid windows\n",
    "                \n",
    "                # Step 6: Extract multichannel fractal features and signals\n",
    "                # fractal_features = []\n",
    "                # signals = []\n",
    "                # for window in window_data:\n",
    "                #     # Extract raw EEG signals\n",
    "                #     if hasattr(window, \"raw_window_signal\") and window.raw_window_signal is not None:\n",
    "                #         signals.append(torch.tensor(window.raw_window_signal.flatten(), dtype=torch.float32))\n",
    "                #     else:\n",
    "                #         signals.append(torch.zeros(1))  # Placeholder if missing\n",
    "\n",
    "                #     # Extract fractal features\n",
    "                #     channel_features = []\n",
    "                #     # if hasattr(window, \"hq\") and window.Dq is not None:\n",
    "                #     #     channel_features.extend(window.Dq.flatten())\n",
    "                #     if hasattr(window, \"Dq\") and window.Dq is not None:\n",
    "                #         channel_features.extend(window.Dq.flatten())\n",
    "\n",
    "                #     fractal_features.append(torch.tensor(channel_features, dtype=torch.float32))\n",
    "                #     # if torch.isnan(fractal_features[-1]).any():\n",
    "                #     #     print(\"here is a nan in {}\".format(participant_idx))\n",
    "                #     #     continue\n",
    "\n",
    "                # # Ensure all feature lengths are the same\n",
    "                # if self.fractal_feature_length is None:\n",
    "                #     self.fractal_feature_length = len(fractal_features[0])\n",
    "\n",
    "                # # Convert to torch tensors and store\n",
    "                # self.features.append(torch.stack(fractal_features))  # Shape: (num_channels, feature_length)\n",
    "                # self.signals.append(torch.stack(signals))  # Shape: (num_channels, signal_length)\n",
    "                # self.labels.append((int(before_label), int(after_label)))\n",
    "                # Step 6: Extract multichannel fractal features and signals\n",
    "                fractal_features = []\n",
    "                signals = []\n",
    "                for window in window_data:\n",
    "                    # Extract raw EEG signals\n",
    "                    if hasattr(window, \"raw_window_signal\") and window.raw_window_signal is not None:\n",
    "                        signals.append(torch.tensor(window.raw_window_signal.flatten(), dtype=torch.float32))\n",
    "                    else:\n",
    "                        signals.append(torch.zeros(1))  # Placeholder if missing\n",
    "\n",
    "                    # Extract fractal features as a 41x41 matrix\n",
    "                    if hasattr(window, \"Dq\") and window.Dq is not None and hasattr(window, \"hq\") and window.hq is not None:\n",
    "                        Dq = torch.tensor(window.Dq, dtype=torch.float32)  # Shape: (41,)\n",
    "                        hq = torch.tensor(window.hq, dtype=torch.float32)  # Shape: (41,)\n",
    "                        \n",
    "                        # Expand both into 41x41 matrices using outer product\n",
    "                        fractal_feature_matrix = torch.outer(Dq, hq)  # Shape: (41, 41)\n",
    "                    else:\n",
    "                        fractal_feature_matrix = torch.zeros((41, 41), dtype=torch.float32)  # Placeholder if missing\n",
    "                    \n",
    "                    fractal_features.append(fractal_feature_matrix)  # Store as 2D matrix\n",
    "\n",
    "                # Ensure all feature lengths are the same\n",
    "                if self.fractal_feature_length is None:\n",
    "                    self.fractal_feature_length = fractal_features[0].shape  # Now (41, 41)\n",
    "\n",
    "                # Convert to torch tensors and store\n",
    "                self.features.append(torch.stack(fractal_features))  # Shape: (num_channels, 41, 41)\n",
    "                self.signals.append(torch.stack(signals))  # Shape: (num_channels, signal_length)\n",
    "                self.labels.append((int(before_label), int(after_label)))\n",
    "\n",
    "\n",
    "    def _validate_labels(self):\n",
    "        \"\"\"Ensure all labels are valid integers 0-3.\"\"\"\n",
    "        valid_before = all(0 <= lbl[0] <= 3 for lbl in self.labels)\n",
    "        valid_after = all(0 <= lbl[1] <= 3 for lbl in self.labels)\n",
    "        if not (valid_before and valid_after):\n",
    "            invalid = [\n",
    "                (i, lbl) for i, lbl in enumerate(self.labels)\n",
    "                if not (0 <= lbl[0] <= 3 and 0 <= lbl[1] <= 3)\n",
    "            ]\n",
    "            raise ValueError(f\"Invalid labels found at indices: {invalid[:10]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return a single data sample (x, y)\"\"\"\n",
    "        x = {\n",
    "            'fractal': self.features[idx],  # Shape: (num_channels, feature_length)\n",
    "            'signal': self.signals[idx]  # Shape: (num_channels, signal_length)\n",
    "        }\n",
    "        y = {\n",
    "            \"before_label\": torch.tensor(self.labels[idx][0], dtype=torch.long),\n",
    "            \"after_label\": torch.tensor(self.labels[idx][1], dtype=torch.long),\n",
    "        }\n",
    "        return x, y\n",
    "\n",
    "# Example Usage\n",
    "dataset = MatFileDataset(\"/Users/athenasaghi/VSProjects/CognitiveFatigueDetection/Prediction/window1000LWT/\")\n",
    "print(f\"Loaded {len(dataset)} valid samples\")\n",
    "\n",
    "# Check shapes\n",
    "x, y = dataset[0]\n",
    "print(f\"Fractal Features Shape: {x['fractal'].shape}\")  # Expected: (num_channels, feature_length)\n",
    "print(f\"Signal Shape: {x['signal'].shape}\")  # Expected: (num_channels, signal_length)\n",
    "print(f\"Labels: {y}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.1392625708912694, Accuracy: 59.16%\n",
      "Epoch 2/100, Loss: 1.0302386450213055, Accuracy: 61.23%\n",
      "Epoch 3/100, Loss: 1.0124052901600682, Accuracy: 60.93%\n",
      "Epoch 4/100, Loss: 1.0098251298416492, Accuracy: 61.37%\n",
      "Epoch 5/100, Loss: 1.0064689821975177, Accuracy: 60.86%\n",
      "Epoch 6/100, Loss: 0.9897971693859544, Accuracy: 61.45%\n",
      "Epoch 7/100, Loss: 0.9713855413503425, Accuracy: 61.74%\n",
      "Epoch 8/100, Loss: 0.983438792616822, Accuracy: 61.08%\n",
      "Epoch 9/100, Loss: 0.9684184872826864, Accuracy: 61.08%\n",
      "Epoch 10/100, Loss: 0.9591253053310306, Accuracy: 62.04%\n",
      "Epoch 11/100, Loss: 0.9642432207284972, Accuracy: 61.30%\n",
      "Epoch 12/100, Loss: 0.9583164384198744, Accuracy: 61.60%\n",
      "Epoch 13/100, Loss: 0.9435403042061384, Accuracy: 61.67%\n",
      "Epoch 14/100, Loss: 0.9406047449555508, Accuracy: 62.11%\n",
      "Epoch 15/100, Loss: 0.9273331442544627, Accuracy: 62.26%\n",
      "Epoch 16/100, Loss: 0.9298028280568678, Accuracy: 61.45%\n",
      "Epoch 17/100, Loss: 0.9206396604693213, Accuracy: 61.52%\n",
      "Epoch 18/100, Loss: 0.9246319615563681, Accuracy: 62.11%\n",
      "Epoch 19/100, Loss: 0.9213281079780223, Accuracy: 61.89%\n",
      "Epoch 20/100, Loss: 0.9178640357283658, Accuracy: 61.96%\n",
      "Epoch 21/100, Loss: 0.9132830833279809, Accuracy: 62.04%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m     fractal_features[torch\u001b[38;5;241m.\u001b[39misnan(fractal_features)] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(fractal_features[\u001b[38;5;241m~\u001b[39mtorch\u001b[38;5;241m.\u001b[39misnan(fractal_features)])\n\u001b[1;32m     56\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 57\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(fractal_features)\n\u001b[1;32m     58\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     59\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[77], line 24\u001b[0m, in \u001b[0;36mFractalCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))))\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))))\n\u001b[0;32m---> 24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x))))\n\u001b[1;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten\u001b[39;00m\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)))\n",
      "File \u001b[0;32m~/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class FractalCNN(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes=4):\n",
    "        super(FractalCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 5 * 5, 256)  # Adjusted for 41x41 input\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_channels = 4  # Adjust based on your dataset\n",
    "model = FractalCNN(num_channels=num_channels).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        x, y = batch\n",
    "        fractal_features = x['fractal'].to(device)  # Shape: (batch_size, num_channels, 41, 41)\n",
    "        labels = y[\"before_label\"].to(device)  # Labels (before_label classification)\n",
    "        \n",
    "        if torch.isinf(fractal_features).any():\n",
    "            fractal_features[torch.isinf(fractal_features)] = torch.max(fractal_features[~torch.isinf(fractal_features)])\n",
    "        if torch.isnan(fractal_features).any():\n",
    "            fractal_features[torch.isnan(fractal_features)] = torch.mean(fractal_features[~torch.isnan(fractal_features)])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(fractal_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader)}, Accuracy: {100 * correct/total:.2f}%\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Evaluate the Model\n",
    "# -------------------------------\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        x, y = batch\n",
    "        fractal_features = x['fractal'].to(device)\n",
    "        labels = y[\"before_label\"].to(device)\n",
    "        \n",
    "        outputs = model(fractal_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct/total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/athenasaghi/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  incorrect execution, including forward and backward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.1293194472789765, Train Accuracy: 56.49%\n",
      "Validation Accuracy: 59.61%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(fractal_features)\n\u001b[1;32m     90\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 91\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     92\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     94\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    523\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[1;32m    290\u001b[0m     tensors,\n\u001b[1;32m    291\u001b[0m     grad_tensors_,\n\u001b[1;32m    292\u001b[0m     retain_graph,\n\u001b[1;32m    293\u001b[0m     create_graph,\n\u001b[1;32m    294\u001b[0m     inputs,\n\u001b[1;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    297\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# -------------------------------\n",
    "# Transformer Model (ViT)\n",
    "# -------------------------------\n",
    "class PatchEmbedding(nn.Module):\n",
    "    \"\"\"Splits input into patches and embeds them for the Transformer\"\"\"\n",
    "    def __init__(self, img_size=41, patch_size=5, in_channels=4, embed_dim=256):\n",
    "        super().__init__()\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches + 1, embed_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)  # (B, embed_dim, num_patches) -> (B, num_patches, embed_dim)\n",
    "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)  # Add classification token\n",
    "        x = torch.cat([cls_tokens, x], dim=1)  # (B, num_patches+1, embed_dim)\n",
    "        x += self.pos_embedding\n",
    "        return x\n",
    "\n",
    "class ViTFractal(nn.Module):\n",
    "    def __init__(self, img_size=41, patch_size=5, in_channels=4, num_classes=4, embed_dim=768, num_heads=12, num_layers=12):\n",
    "        super().__init__()\n",
    "        self.patch_embedding = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=1024)\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embedding(x)\n",
    "        x = self.transformer(x)[:, 0]\n",
    "        x = self.mlp_head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Load Dataset and Split\n",
    "# -------------------------------\n",
    "batch_size = 32\n",
    "dataset = MatFileDataset(\"/Users/athenasaghi/VSProjects/CognitiveFatigueDetection/Prediction/window1000LWT/\")\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# -------------------------------\n",
    "# Train the Model\n",
    "# -------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_channels = 4\n",
    "model = ViTFractal(in_channels=num_channels).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.0003)\n",
    "optimizer  = optim.SGD(model.parameters(), lr=0.0003, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        fractal_features = x['fractal'].to(device)  # Shape: (batch_size, num_channels, 41, 41)\n",
    "        labels = y[\"before_label\"].to(device)  # Labels (before_label classification)\n",
    "        \n",
    "        if torch.isinf(fractal_features).any():\n",
    "            fractal_features[torch.isinf(fractal_features)] = torch.max(fractal_features[~torch.isinf(fractal_features)])\n",
    "        if torch.isnan(fractal_features).any():\n",
    "            fractal_features[torch.isnan(fractal_features)] = torch.mean(fractal_features[~torch.isnan(fractal_features)])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(fractal_features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Validation\n",
    "    # -------------------------------\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, y = batch\n",
    "            fractal_features = x['fractal'].to(device)\n",
    "            labels = y[\"before_label\"].to(device)\n",
    "            \n",
    "            outputs = model(fractal_features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# -------------------------------\n",
    "# Test the Model\n",
    "# -------------------------------\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, y = batch\n",
    "        fractal_features = x['fractal'].to(device)\n",
    "        labels = y[\"before_label\"].to(device)\n",
    "        \n",
    "        outputs = model(fractal_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.58\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "dataset = MatFileDataset(\"/Users/athenasaghi/VSProjects/CognitiveFatigueDetection/Prediction/window1000LWT/\")\n",
    "\n",
    "# Convert dataset to numpy arrays\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    x, y = dataset[i]\n",
    "    fractal_features = x['fractal'].numpy().flatten()  # Flatten (4, 41, 41) → (4 * 41 * 41,)\n",
    "    features.append(fractal_features)\n",
    "    labels.append(y[\"before_label\"].item())\n",
    "\n",
    "features = np.array(features)  # Shape: (num_samples, feature_dim)\n",
    "labels = np.array(labels)  # Shape: (num_samples,)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "if np.isnan(X_train).any():\n",
    "    X_train[np.isnan(X_train)] = np.nanmax(X_train[~np.isnan(X_train)])\n",
    "if np.isinf(X_train).any():\n",
    "    X_train[np.isinf(X_train)] = np.nanmax(X_train[~np.isinf(X_train)])\n",
    "\n",
    "# Initialize and train KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=12)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# # Validation Accuracy\n",
    "# if np.isnan(X_val).any():\n",
    "#     X_val[np.isnan(X_val)] = np.nanmax(X_val[~np.isnan(X_val)])\n",
    "# if np.isinf(X_val).any():\n",
    "#     X_val[np.isinf(X_val)] = np.nanmax(X_val[~np.isinf(X_val)])\n",
    "# y_val_pred = knn.predict(X_val)\n",
    "# val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "# print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
    "\n",
    "# Test Accuracy\n",
    "if np.isnan(X_test).any():\n",
    "    X_test[np.isnan(X_test)] = np.nanmax(X_test[~np.isnan(X_test)])\n",
    "if np.isinf(X_test).any():\n",
    "    X_test[np.isinf(X_test)] = np.nanmax(X_test[~np.isinf(X_test)])\n",
    "y_test_pred = knn.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MatFileDataset(\"/Users/athenasaghi/VSProjects/CognitiveFatigueDetection/Prediction/window50/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "# Convert dataset to numpy arrays\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    x, y = dataset[i]\n",
    "    fractal_features = x['fractal'].numpy().flatten()  # Flatten (4, 41, 41) → (4 * 41 * 41,)\n",
    "    features.append(fractal_features)\n",
    "    labels.append(y[\"before_label\"].item())\n",
    "\n",
    "features = np.array(features)  # Shape: (num_samples, feature_dim)\n",
    "labels = np.array(labels)  # Shape: (num_samples,)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "if np.isnan(X_train).any():\n",
    "    X_train[np.isnan(X_train)] = np.nanmax(X_train[~np.isnan(X_train)])\n",
    "if np.isinf(X_train).any():\n",
    "    X_train[np.isinf(X_train)] = np.nanmax(X_train[~np.isinf(X_train)])\n",
    "\n",
    "# Initialize and train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=20, max_depth=20, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "if np.isnan(X_test).any():\n",
    "    X_test[np.isnan(X_test)] = np.nanmax(X_test[~np.isnan(X_test)])\n",
    "if np.isinf(X_test).any():\n",
    "    X_test[np.isinf(X_test)] = np.nanmax(X_test[~np.isinf(X_test)])\n",
    "\n",
    "# Test Accuracy\n",
    "y_test_pred = rf.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6795 valid samples\n",
      "Fractal Features Shape: torch.Size([4, 41])\n",
      "Signal Shape: torch.Size([4, 200])\n",
      "Labels: {'before_label': tensor(0), 'after_label': tensor(0)}\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import scipy.io as sio\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# class MatFileDataset(Dataset):\n",
    "#     def __init__(self, directory):\n",
    "#         self.features = []  # Will store multi-channel fractal features (num_channels, feature_length)\n",
    "#         self.signals = []   # Will store multi-channel EEG signals (num_channels, signal_length)\n",
    "#         self.labels = []    # Labels for each window (before_label, after_label)\n",
    "#         self.num_channels = 4  # Number of channels (4 separate .mat files)\n",
    "#         self.fractal_feature_length = None  # To determine feature length from first valid data\n",
    "\n",
    "#         self._load_data(directory)\n",
    "#         self._validate_labels()\n",
    "\n",
    "#     def _load_data(self, directory):\n",
    "#         \"\"\"Load all four channels separately and align participant data correctly.\"\"\"\n",
    "#         # Step 1: Find all .mat files (assuming four files exist, one per channel)\n",
    "#         mat_files = sorted([os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".mat\")])\n",
    "#         if len(mat_files) != self.num_channels:\n",
    "#             raise ValueError(f\"Expected {self.num_channels} .mat files, but found {len(mat_files)}\")\n",
    "\n",
    "#         # Step 2: Load data from all channels\n",
    "#         all_channels_data = [sio.loadmat(f, struct_as_record=False, squeeze_me=True) for f in mat_files]\n",
    "\n",
    "#         # Step 3: Check if all files contain 'all_window_features'\n",
    "#         for i, mat_data in enumerate(all_channels_data):\n",
    "#             if \"all_window_features\" not in mat_data:\n",
    "#                 raise ValueError(f\"Missing 'all_window_features' in file {mat_files[i]}\")\n",
    "\n",
    "#         # Step 4: Process participant data by aligning across channels\n",
    "#         num_participants = len(all_channels_data[0][\"all_window_features\"])\n",
    "        \n",
    "#         for participant_idx in range(num_participants):\n",
    "#             # Extract participant data from each channel\n",
    "#             participant_windows = [\n",
    "#                 mat_data[\"all_window_features\"][participant_idx] for mat_data in all_channels_data\n",
    "#             ]\n",
    "\n",
    "#             # Skip if any channel is missing participant data\n",
    "#             if any(p is None for p in participant_windows):\n",
    "#                 continue\n",
    "\n",
    "#             # Step 5: Ensure that windows are aligned across channels\n",
    "#             num_windows = len(participant_windows[0])  # Get window count from first channel\n",
    "#             for win_idx in range(num_windows):\n",
    "#                 # Extract corresponding window from each channel\n",
    "#                 window_data = [participant_windows[ch][win_idx] for ch in range(self.num_channels)]\n",
    "\n",
    "#                 # Extract labels from the first channel only (assuming labels are the same across channels)\n",
    "#                 before_label = getattr(window_data[0], \"before_label\", None)\n",
    "#                 after_label = getattr(window_data[0], \"after_label\", None)\n",
    "\n",
    "#                 # Validate labels\n",
    "#                 if (before_label is None or after_label is None or \n",
    "#                     not (0 <= before_label <= 3) or not (0 <= after_label <= 3)):\n",
    "#                     continue  # Skip invalid windows\n",
    "                \n",
    "#                 # **Map labels:**\n",
    "#                 before_label = 0 if before_label == 0 else 1  # 0 -> 0, (1,2,3) -> 1\n",
    "#                 after_label = 0 if after_label == 0 else 1  # 0 -> 0, (1,2,3) -> 1\n",
    "\n",
    "#                 # Step 6: Extract multichannel fractal features and signals\n",
    "#                 fractal_features = []\n",
    "#                 signals = []\n",
    "#                 for window in window_data:\n",
    "#                     # Extract raw EEG signals\n",
    "#                     if hasattr(window, \"raw_window_signal\") and window.raw_window_signal is not None:\n",
    "#                         signals.append(torch.tensor(window.raw_window_signal.flatten(), dtype=torch.float32))\n",
    "#                     else:\n",
    "#                         signals.append(torch.zeros(1))  # Placeholder if missing\n",
    "\n",
    "#                     # Extract fractal features\n",
    "#                     channel_features = []\n",
    "#                     # if hasattr(window, \"hq\") and window.Dq is not None:\n",
    "#                     #     channel_features.extend(window.Dq.flatten())\n",
    "#                     if hasattr(window, \"Dq\") and window.hq is not None:\n",
    "#                         channel_features.extend(window.hq.flatten())\n",
    "\n",
    "#                     fractal_features.append(torch.tensor(channel_features, dtype=torch.float32))\n",
    "\n",
    "#                 # Ensure all feature lengths are the same\n",
    "#                 if self.fractal_feature_length is None:\n",
    "#                     self.fractal_feature_length = len(fractal_features[0])\n",
    "\n",
    "#                 # Convert to torch tensors and store\n",
    "#                 self.features.append(torch.stack(fractal_features))  # Shape: (num_channels, feature_length)\n",
    "#                 self.signals.append(torch.stack(signals))  # Shape: (num_channels, signal_length)\n",
    "#                 self.labels.append((int(before_label), int(after_label)))\n",
    "\n",
    "#     def _validate_labels(self):\n",
    "#         \"\"\"Ensure all labels are valid integers 0-1 after mapping.\"\"\"\n",
    "#         valid_before = all(lbl[0] in {0, 1} for lbl in self.labels)\n",
    "#         valid_after = all(lbl[1] in {0, 1} for lbl in self.labels)\n",
    "#         if not (valid_before and valid_after):\n",
    "#             invalid = [\n",
    "#                 (i, lbl) for i, lbl in enumerate(self.labels)\n",
    "#                 if lbl[0] not in {0, 1} or lbl[1] not in {0, 1}\n",
    "#             ]\n",
    "#             raise ValueError(f\"Invalid labels found at indices: {invalid[:10]}\")\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.features)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         \"\"\"Return a single data sample (x, y)\"\"\"\n",
    "#         x = {\n",
    "#             'fractal': self.features[idx],  # Shape: (num_channels, feature_length)\n",
    "#             'signal': self.signals[idx]  # Shape: (num_channels, signal_length)\n",
    "#         }\n",
    "#         y = {\n",
    "#             \"before_label\": torch.tensor(self.labels[idx][0], dtype=torch.long),\n",
    "#             \"after_label\": torch.tensor(self.labels[idx][1], dtype=torch.long),\n",
    "#         }\n",
    "#         return x, y\n",
    "\n",
    "# # Example Usage\n",
    "# dataset = MatFileDataset(\"/Users/athenasaghi/VSProjects/CognitiveFatigueDetection/Prediction/window200/\")\n",
    "# print(f\"Loaded {len(dataset)} valid samples\")\n",
    "\n",
    "# # Check shapes\n",
    "# x, y = dataset[0]\n",
    "# print(f\"Fractal Features Shape: {x['fractal'].shape}\")  # Expected: (num_channels, feature_length)\n",
    "# print(f\"Signal Shape: {x['signal'].shape}\")  # Expected: (num_channels, signal_length)\n",
    "# print(f\"Labels: {y}\")  # Expected: {0,1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: NaNs=57, Infs=9972\n",
      "Training Accuracy: 58.70%\n",
      "Test Data: NaNs=57, Infs=9972\n",
      "Test Accuracy: 58.70%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def preprocess_data(fractal, dataset_name=\"Dataset\"):\n",
    "    fractal = fractal.numpy().reshape(fractal.shape[0], -1)  # Convert to NumPy and flatten\n",
    "    \n",
    "    # Count NaNs and Infs\n",
    "    num_nans = np.isnan(fractal).sum()\n",
    "    num_infs = np.isinf(fractal).sum()\n",
    "    print(f\"{dataset_name}: NaNs={num_nans}, Infs={num_infs}\")\n",
    "\n",
    "    # Remove rows with NaNs or Infs\n",
    "    clean_mask = ~np.isnan(fractal).any(axis=1) & ~np.isinf(fractal).any(axis=1)\n",
    "    fractal_cleaned = fractal[clean_mask]\n",
    "\n",
    "    return fractal_cleaned, clean_mask  # Return mask to apply on labels\n",
    "\n",
    "# Load and preprocess training data\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "x_train, y_train = zip(*[(batch[0]['fractal'], batch[1]['before_label']) for batch in train_loader])\n",
    "fractal_train, mask_train = preprocess_data(torch.cat(x_train, dim=0), \"Training Data\")\n",
    "labels_train = torch.cat(y_train, dim=0).numpy().reshape(-1)[mask_train]  # Apply mask\n",
    "\n",
    "# Train KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(fractal_train, labels_train)\n",
    "\n",
    "# Evaluate on training data\n",
    "train_accuracy = accuracy_score(labels_train, knn.predict(fractal_train))\n",
    "print(f\"Training Accuracy: {train_accuracy:.2%}\")\n",
    "\n",
    "# Load and preprocess test data\n",
    "x_test, y_test = zip(*[(batch[0]['fractal'], batch[1]['before_label']) for batch in test_loader])\n",
    "fractal_test, mask_test = preprocess_data(torch.cat(x_test, dim=0), \"Test Data\")\n",
    "labels_test = torch.cat(y_test, dim=0).numpy().reshape(-1)[mask_test]  # Apply mask\n",
    "\n",
    "# Evaluate on test data\n",
    "test_accuracy = accuracy_score(labels_test, knn.predict(fractal_test))\n",
    "print(f\"Test Accuracy: {test_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Warning: NaN/Inf detected at participant 0, window 522, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 2, window 335, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 3, window 1, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 3, window 20, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 3, window 205, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 3, window 269, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 3, window 455, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 3, window 577, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 5, window 0, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 5, window 135, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 5, window 216, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 5, window 523, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 6, window 153, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 6, window 250, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 7, window 22, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 7, window 47, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 7, window 64, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 7, window 152, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 7, window 267, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 7, window 353, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 7, window 354, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 7, window 393, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 7, window 404, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 7, window 412, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 9, window 0, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 9, window 75, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 9, window 82, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 9, window 478, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 10, window 27, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 10, window 115, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 10, window 189, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 10, window 354, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 10, window 361, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 10, window 443, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 11, window 92, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 11, window 184, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 11, window 410, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 11, window 414, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 11, window 456, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 11, window 457, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 11, window 493, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 12, window 137, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 14, window 182, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 14, window 414, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 15, window 33, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 15, window 50, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 15, window 56, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 15, window 64, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 15, window 76, replacing with zero\n",
      "⚠️ Warning: NaN/Inf detected at participant 15, window 110, replacing with zero\n",
      "Loaded 9812 valid samples\n",
      "\n",
      "Stacked Model Classification Accuracy: 0.3785\n",
      "\n",
      "Per-Class Accuracy:\n",
      "Label 0: 0.4637\n",
      "Label 1: 0.2435\n",
      "Label 2: 0.2625\n",
      "Label 3: 0.3028\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.46      0.55      1117\n",
      "           1       0.17      0.24      0.20       308\n",
      "           2       0.20      0.26      0.23       320\n",
      "           3       0.19      0.30      0.23       218\n",
      "\n",
      "    accuracy                           0.38      1963\n",
      "   macro avg       0.31      0.32      0.30      1963\n",
      "weighted avg       0.47      0.38      0.41      1963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class MatFileDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        self.num_channels = 4  \n",
    "\n",
    "        self._load_data(directory)\n",
    "        self._validate_labels()\n",
    "\n",
    "    def _load_data(self, directory):\n",
    "        mat_files = sorted([os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".mat\")])\n",
    "        if len(mat_files) != self.num_channels:\n",
    "            raise ValueError(f\"Expected {self.num_channels} .mat files, but found {len(mat_files)}\")\n",
    "\n",
    "        all_channels_data = [sio.loadmat(f, struct_as_record=False, squeeze_me=True) for f in mat_files]\n",
    "        num_participants = len(all_channels_data[0][\"all_window_features\"])\n",
    "\n",
    "        for participant_idx in range(num_participants):\n",
    "            participant_windows = [mat_data[\"all_window_features\"][participant_idx] for mat_data in all_channels_data]\n",
    "            if any(p is None for p in participant_windows):\n",
    "                continue\n",
    "\n",
    "            num_windows = len(participant_windows[0])\n",
    "            for win_idx in range(num_windows):\n",
    "                window_data = [participant_windows[ch][win_idx] for ch in range(self.num_channels)]\n",
    "\n",
    "                before_label = getattr(window_data[0], \"before_label\", None)\n",
    "                after_label = getattr(window_data[0], \"after_label\", None)\n",
    "                if (before_label is None or after_label is None or not (0 <= before_label <= 3) or not (0 <= after_label <= 3)):\n",
    "                    continue  \n",
    "\n",
    "                fractal_features = []\n",
    "                for ch, window in enumerate(window_data):\n",
    "                    channel_features = []\n",
    "                    if hasattr(window, \"Dq\") and window.hq is not None:\n",
    "                        channel_features.extend(window.hq.flatten())\n",
    "\n",
    "                    channel_features = np.array(channel_features, dtype=np.float32)\n",
    "\n",
    "                    # **Fix NaN & Inf by replacing with column mean**\n",
    "                    nan_mask = np.isnan(channel_features) | np.isinf(channel_features)\n",
    "                    mean_value = np.nanmean(channel_features) if np.any(~nan_mask) else 0\n",
    "                    channel_features[nan_mask] = mean_value\n",
    "\n",
    "                    fractal_features.append(channel_features)\n",
    "\n",
    "                # Concatenate features from all channels\n",
    "                combined_features = np.concatenate(fractal_features)\n",
    "                \n",
    "                # **Final NaN/Inf Check**\n",
    "                if np.isnan(combined_features).any() or np.isinf(combined_features).any():\n",
    "                    print(f\"⚠️ Warning: NaN/Inf detected at participant {participant_idx}, window {win_idx}, replacing with zero\")\n",
    "                    combined_features[np.isnan(combined_features)] = 0\n",
    "                    combined_features[np.isinf(combined_features)] = 0\n",
    "                \n",
    "                self.features.append(combined_features)\n",
    "                self.labels.append(int(after_label))\n",
    "\n",
    "    def _validate_labels(self):\n",
    "        valid_labels = all(0 <= lbl <= 3 for lbl in self.labels)\n",
    "        if not valid_labels:\n",
    "            raise ValueError(\"Invalid labels detected.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Load dataset\n",
    "dataset = MatFileDataset(\"/Users/athenasaghi/VSProjects/CognitiveFatigueDetection/Prediction/window150/\")\n",
    "print(f\"Loaded {len(dataset)} valid samples\")\n",
    "\n",
    "# Extract features and labels\n",
    "features = np.array(dataset.features)\n",
    "labels = np.array(dataset.labels)\n",
    "\n",
    "# **Final Debugging: Check for NaN/Inf Before Scaling**\n",
    "if np.isnan(features).any() or np.isinf(features).any():\n",
    "    print(\"⚠️ NaN or Inf detected in features after extraction. Replacing with column mean.\")\n",
    "    col_means = np.nanmean(features, axis=0)\n",
    "    nan_indices = np.where(np.isnan(features))\n",
    "    features[nan_indices] = np.take(col_means, nan_indices[1])\n",
    "    features[np.isinf(features)] = np.nanmax(features[np.isfinite(features)])\n",
    "\n",
    "# **Split dataset**\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# **Scale features using RobustScaler**\n",
    "# scaler = RobustScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# **Apply SMOTE to fix class imbalance**\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# **Feature Selection using RandomForest**\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "num_top_features = int(0.9 * len(importances))  # Keep 90% of important features\n",
    "selected_features = sorted_idx[:num_top_features]\n",
    "\n",
    "X_train_selected = X_train[:, selected_features]\n",
    "X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "# **Dimensionality Reduction using PCA**\n",
    "pca = PCA(n_components=0.99)  # Keep 99% variance\n",
    "X_train_pca = pca.fit_transform(X_train_selected)\n",
    "X_test_pca = pca.transform(X_test_selected)\n",
    "\n",
    "# **Train Optimized Classifier (Stacking XGBoost + GradientBoosting)**\n",
    "base_learners = [\n",
    "    ('xgb', XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=8, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=300, learning_rate=0.05, max_depth=8, random_state=42))\n",
    "]\n",
    "stacked_model = StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression())\n",
    "stacked_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# **Predict**\n",
    "y_pred = stacked_model.predict(X_test_pca)\n",
    "\n",
    "# **Evaluate performance**\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nStacked Model Classification Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# **Compute per-class accuracy**\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "for label, acc in enumerate(class_accuracies):\n",
    "    print(f\"Label {label}: {acc:.4f}\")\n",
    "\n",
    "# **Print detailed classification report**\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CognitiveFatigue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
