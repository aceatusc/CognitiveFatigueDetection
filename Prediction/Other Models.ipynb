{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import torch\n",
    "# import scipy.io as sio\n",
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "class MatFileDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.features = []  # To store 4-channel fractal features\n",
    "        self.signals = []   # To store 4-channel raw signals\n",
    "        self.labels = []    # To store labels\n",
    "        self.fractal_feature_length = None\n",
    "        self._load_data(directory)\n",
    "        self._validate_labels()\n",
    "\n",
    "    def _load_data(self, directory):\n",
    "        # Temporary storage for grouping channels\n",
    "        grouped_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "        # Step 1: Read all files and group by participant and window\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".mat\"):\n",
    "                filepath = os.path.join(directory, filename)\n",
    "                mat_data = sio.loadmat(filepath, struct_as_record=False, squeeze_me=True)\n",
    "\n",
    "                all_window_features = mat_data.get(\"all_window_features\")\n",
    "                if all_window_features is None:\n",
    "                    continue\n",
    "\n",
    "                # Extract the channel name from the file name\n",
    "                channel_name = filename.split('_')[-2]  # Assumes \"TP10\" or similar is always at the second last position\n",
    "\n",
    "                for participant_index, participant_data in enumerate(all_window_features):\n",
    "                    if participant_data is None:\n",
    "                        continue\n",
    "\n",
    "                    for window_index, window in enumerate(participant_data):\n",
    "                        # Extract labels first for filtering\n",
    "                        before_label = getattr(window, \"before_label\", None)\n",
    "                        after_label = getattr(window, \"after_label\", None)\n",
    "                        \n",
    "                        # Filter condition: both labels must exist and be <=3\n",
    "                        if (before_label is None or \n",
    "                            after_label is None or \n",
    "                            not (0 <= before_label <= 3) or \n",
    "                            not (0 <= after_label <= 3)):\n",
    "                            continue\n",
    "\n",
    "                        # Extract features and raw signals\n",
    "                        fractal_features = []\n",
    "                        raw_signals = []\n",
    "\n",
    "                        if hasattr(window, \"raw_window_signal\") and window.raw_window_signal is not None:\n",
    "                            raw_signals = window.raw_window_signal.flatten()\n",
    "                        if hasattr(window, \"Dq\") and window.Dq is not None:\n",
    "                            fractal_features = window.Dq.flatten()\n",
    "                        \n",
    "                        # Store data temporarily, grouped by participant and window\n",
    "                        grouped_data[(participant_index, window_index)][\"channels\"].append(channel_name)\n",
    "                        grouped_data[(participant_index, window_index)][\"fractal\"].append(torch.tensor(fractal_features, dtype=torch.float32))\n",
    "                        grouped_data[(participant_index, window_index)][\"signal\"].append(torch.tensor(raw_signals, dtype=torch.float32))\n",
    "                        grouped_data[(participant_index, window_index)][\"label\"] = (int(before_label), int(after_label))\n",
    "                        \n",
    "                        # Set fractal feature length from the first valid feature\n",
    "                        if self.fractal_feature_length is None and len(fractal_features) > 0:\n",
    "                            self.fractal_feature_length = len(fractal_features)\n",
    "\n",
    "        # Step 2: Combine data for all channels\n",
    "        for (participant_index, window_index), data in grouped_data.items():\n",
    "            channels = data[\"channels\"]\n",
    "            if len(channels) != 4:  # Ensure all 4 channels are present\n",
    "                continue\n",
    "            \n",
    "            # Stack fractal features and signals along a new dimension (channel dimension)\n",
    "            fractal_features = torch.stack(data[\"fractal\"], dim=0)  # Shape: (4, fractal_feature_length)\n",
    "            raw_signals = torch.stack(data[\"signal\"], dim=0)        # Shape: (4, signal_length)\n",
    "\n",
    "            self.features.append(fractal_features)\n",
    "            self.signals.append(raw_signals)\n",
    "            self.labels.append(data[\"label\"])\n",
    "\n",
    "    def _validate_labels(self):\n",
    "        \"\"\"Ensure all labels are valid integers 0-3\"\"\"\n",
    "        valid_before = all(0 <= lbl[0] <= 3 for lbl in self.labels)\n",
    "        valid_after = all(0 <= lbl[1] <= 3 for lbl in self.labels)\n",
    "        if not (valid_before and valid_after):\n",
    "            invalid = [\n",
    "                (i, lbl) for i, lbl in enumerate(self.labels)\n",
    "                if not (0 <= lbl[0] <= 3 and 0 <= lbl[1] <= 3)\n",
    "            ]\n",
    "            raise ValueError(f\"Invalid labels found at indices: {invalid[:10]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = {\n",
    "            'fractal': self.features[idx],  # Shape: (4, fractal_feature_length)\n",
    "            'signal': self.signals[idx],    # Shape: (4, signal_length)\n",
    "        }\n",
    "        y = {\n",
    "            \"before_label\": torch.tensor(self.labels[idx][0], dtype=torch.long),\n",
    "            \"after_label\": torch.tensor(self.labels[idx][1], dtype=torch.long),\n",
    "        }\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28908 valid samples\n"
     ]
    }
   ],
   "source": [
    "dataset = MatFileDataset(\"/Users/athenasaghi/VSProjects/CognitiveFatigueDetection/Prediction/\")\n",
    "print(f\"Loaded {len(dataset)} valid samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2503, Acc: 0.5640\n",
      "Epoch [2/10], Loss: 1.1136, Acc: 0.6339\n",
      "Epoch [3/10], Loss: 1.0456, Acc: 0.6337\n",
      "Epoch [4/10], Loss: 1.0126, Acc: 0.6339\n",
      "Epoch [5/10], Loss: 0.9957, Acc: 0.6341\n",
      "Epoch [6/10], Loss: 0.9870, Acc: 0.6338\n",
      "Epoch [7/10], Loss: 0.9815, Acc: 0.6338\n",
      "Epoch [8/10], Loss: 0.9778, Acc: 0.6338\n",
      "Epoch [9/10], Loss: 0.9750, Acc: 0.6339\n",
      "Epoch [10/10], Loss: 0.9730, Acc: 0.6340\n",
      "LSTM Test Accuracy: 0.6279\n",
      "LSTM Test Precision: 0.3942\n",
      "LSTM Test Recall: 0.6279\n",
      "LSTM Test F1 Score: 0.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/athenasaghi/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/athenasaghi/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test Accuracy: 0.6129\n",
      "XGBoost Test Precision: 0.4693\n",
      "XGBoost Test Recall: 0.6129\n",
      "XGBoost Test F1 Score: 0.4927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/athenasaghi/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.6262\n",
      "Random Forest Test Precision: 0.4388\n",
      "Random Forest Test Recall: 0.6262\n",
      "Random Forest Test F1 Score: 0.4857\n",
      "SVM Test Accuracy: 0.6279\n",
      "SVM Test Precision: 0.3942\n",
      "SVM Test Recall: 0.6279\n",
      "SVM Test F1 Score: 0.4843\n",
      "\n",
      "Model Comparison:\n",
      "LSTM Accuracy: 0.6279, Precision: 0.3942, Recall: 0.6279, F1 Score: 0.4843\n",
      "XGBoost Accuracy: 0.6129, Precision: 0.4693, Recall: 0.6129, F1 Score: 0.4927\n",
      "Random Forest Accuracy: 0.6262, Precision: 0.4388, Recall: 0.6262, F1 Score: 0.4857\n",
      "SVM Accuracy: 0.6279, Precision: 0.3942, Recall: 0.6279, F1 Score: 0.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/athenasaghi/anaconda3/envs/CognitiveFatigue/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Dataset split\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Helper function to preprocess batches\n",
    "def preprocess_data(loader):\n",
    "    X, y = [], []\n",
    "    for batch in loader:\n",
    "        x, labels = batch\n",
    "        label = labels['before_label']\n",
    "\n",
    "        # Handle inf/nan values in 'fractal'\n",
    "        if np.isinf(x['fractal']).any():\n",
    "            max_finite = torch.max(x['fractal'][~torch.isinf(x['fractal'])])\n",
    "            x['fractal'][torch.isinf(x['fractal'])] = max_finite\n",
    "        if np.isnan(x['fractal']).any():\n",
    "            mean_finite = torch.mean(x['fractal'][~torch.isnan(x['fractal'])])\n",
    "            x['fractal'][torch.isnan(x['fractal'])] = mean_finite\n",
    "\n",
    "        inputs = x['fractal']\n",
    "        X.append(inputs.numpy().reshape(inputs.shape[0], -1))\n",
    "        y.append(label.numpy())\n",
    "\n",
    "    return np.vstack(X), np.hstack(y)\n",
    "\n",
    "# Preprocess data for non-PyTorch models\n",
    "X_train, y_train = preprocess_data(train_loader)\n",
    "X_val, y_val = preprocess_data(val_loader)\n",
    "X_test, y_test = preprocess_data(test_loader)\n",
    "\n",
    "# Multichannel LSTM model definition\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)  # h_n: hidden state of the last LSTM cell\n",
    "        out = self.fc(h_n[-1])     # Fully connected layer for classification\n",
    "        return out\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "num_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "lstm_model = LSTMClassifier(41, hidden_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(lstm_model.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    lstm_model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        x, labels = batch\n",
    "        label = labels['before_label']\n",
    "\n",
    "        # Handle inf/nan values in 'fractal'\n",
    "        if np.isinf(x['fractal']).any():\n",
    "            max_finite = torch.max(x['fractal'][~torch.isinf(x['fractal'])])\n",
    "            x['fractal'][torch.isinf(x['fractal'])] = max_finite\n",
    "        if np.isnan(x['fractal']).any():\n",
    "            mean_finite = torch.mean(x['fractal'][~torch.isnan(x['fractal'])])\n",
    "            x['fractal'][torch.isnan(x['fractal'])] = mean_finite\n",
    "\n",
    "        # Reshape inputs to (batch_size, seq_length, num_channels)\n",
    "        inputs = x['fractal'].float()  # Ensure inputs are float\n",
    "        labels = label.long()  # Ensure labels are of type long\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = lstm_model(inputs)  # Forward pass\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        total_acc += (preds == labels).float().mean().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}, Acc: {total_acc / len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluate LSTM\n",
    "lstm_model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, labels = batch\n",
    "        label = labels['before_label']\n",
    "\n",
    "        # Handle inf/nan values in 'fractal'\n",
    "        if np.isinf(x['fractal']).any():\n",
    "            max_finite = torch.max(x['fractal'][~torch.isinf(x['fractal'])])\n",
    "            x['fractal'][torch.isinf(x['fractal'])] = max_finite\n",
    "        if np.isnan(x['fractal']).any():\n",
    "            mean_finite = torch.mean(x['fractal'][~torch.isnan(x['fractal'])])\n",
    "            x['fractal'][torch.isnan(x['fractal'])] = mean_finite\n",
    "\n",
    "        # Reshape inputs to (batch_size, seq_length, num_channels)\n",
    "        inputs = x['fractal'].float()\n",
    "        labels = label.long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = lstm_model(inputs)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        # Append to true and predicted lists\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "lstm_acc = accuracy_score(y_true, y_pred)\n",
    "lstm_precision = precision_score(y_true, y_pred, average='weighted')\n",
    "lstm_recall = recall_score(y_true, y_pred, average='weighted')\n",
    "lstm_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"LSTM Test Accuracy: {lstm_acc:.4f}\")\n",
    "print(f\"LSTM Test Precision: {lstm_precision:.4f}\")\n",
    "print(f\"LSTM Test Recall: {lstm_recall:.4f}\")\n",
    "print(f\"LSTM Test F1 Score: {lstm_f1:.4f}\")\n",
    "\n",
    "# Train and evaluate XGBoost\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "xgb_acc = accuracy_score(y_test, xgb_preds)\n",
    "xgb_precision = precision_score(y_test, xgb_preds, average='weighted')\n",
    "xgb_recall = recall_score(y_test, xgb_preds, average='weighted')\n",
    "xgb_f1 = f1_score(y_test, xgb_preds, average='weighted')\n",
    "\n",
    "print(f\"XGBoost Test Accuracy: {xgb_acc:.4f}\")\n",
    "print(f\"XGBoost Test Precision: {xgb_precision:.4f}\")\n",
    "print(f\"XGBoost Test Recall: {xgb_recall:.4f}\")\n",
    "print(f\"XGBoost Test F1 Score: {xgb_f1:.4f}\")\n",
    "\n",
    "# Train and evaluate Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_preds)\n",
    "rf_precision = precision_score(y_test, rf_preds, average='weighted')\n",
    "rf_recall = recall_score(y_test, rf_preds, average='weighted')\n",
    "rf_f1 = f1_score(y_test, rf_preds, average='weighted')\n",
    "\n",
    "print(f\"Random Forest Test Accuracy: {rf_acc:.4f}\")\n",
    "print(f\"Random Forest Test Precision: {rf_precision:.4f}\")\n",
    "print(f\"Random Forest Test Recall: {rf_recall:.4f}\")\n",
    "print(f\"Random Forest Test F1 Score: {rf_f1:.4f}\")\n",
    "\n",
    "# Train and evaluate SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_preds = svm_model.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, svm_preds)\n",
    "svm_precision = precision_score(y_test, svm_preds, average='weighted')\n",
    "svm_recall = recall_score(y_test, svm_preds, average='weighted')\n",
    "svm_f1 = f1_score(y_test, svm_preds, average='weighted')\n",
    "\n",
    "print(f\"SVM Test Accuracy: {svm_acc:.4f}\")\n",
    "print(f\"SVM Test Precision: {svm_precision:.4f}\")\n",
    "print(f\"SVM Test Recall: {svm_recall:.4f}\")\n",
    "print(f\"SVM Test F1 Score: {svm_f1:.4f}\")\n",
    "\n",
    "# Summary of results\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"LSTM Accuracy: {lstm_acc:.4f}, Precision: {lstm_precision:.4f}, Recall: {lstm_recall:.4f}, F1 Score: {lstm_f1:.4f}\")\n",
    "print(f\"XGBoost Accuracy: {xgb_acc:.4f}, Precision: {xgb_precision:.4f}, Recall: {xgb_recall:.4f}, F1 Score: {xgb_f1:.4f}\")\n",
    "print(f\"Random Forest Accuracy: {rf_acc:.4f}, Precision: {rf_precision:.4f}, Recall: {rf_recall:.4f}, F1 Score: {rf_f1:.4f}\")\n",
    "print(f\"SVM Accuracy: {svm_acc:.4f}, Precision: {svm_precision:.4f}, Recall: {svm_recall:.4f}, F1 Score: {svm_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CognitiveFatigue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
